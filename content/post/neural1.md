---
title: "ニューラルネットワークと深層学習のお勉強(1)"
date: 2018-12-30T00:32:08+09:00
draft: false
tags: ["Neural Network","機械学習","Python3"]
categories: ["機械学習","Python3"]
---

「ニューラルネットワークと深層学習( http://nnadl-ja.github.io/nnadl_site_ja/index.html )」を読んで勉強したことを書いていこうと思います。
これは自分の脳内整理用のメモであるため、内容が端折られたり抜けてたりしています。学習する際はすばらしき原文を読まれることをお勧めいたします。


## パーセプトロン
今日ではパーセプトロン以外の人口ニューロンモデル(多くはシグモイドニューロン？)を使うことが一般的だが、シグモイドニューロンを理解するにはパーセプトロンを理解することが大事である。

パーセプトロンは複数の入力を取る。入力は1または0。
出力は1つで、1または0。
入力ベクトル$x$、重みベクトル$w$、バイアス$b$があって

$$
\mathrm{output} =
\left\\{
\begin{array}{}
0 & \mathrm{ if } \; w \cdot x + b \leq 0 \\\\\\
1 &  \mathrm{ if } \; w \cdot x + b \gt 0
\end{array}
\right.
$$

パーセプトロンを層にわけて判断させると複雑なものや抽象的なものも判定できる。パーセプトロン1つでNANDと同値の挙動をさせることができるので任意の論理関数を計算できる。

## シグモイドニュートロン
パーセプトロンのネットワークでは微小な入力変化で大きな出力の変化が生まれてしまう。これを解決したのがシグモイドニューロン。出力は$\sigma \( w \cdot x  + b )$。$ \sigma $はシグモイド関数(もしくはロジスティック関数)と呼ばれている。


$$
σ ( z ) \equiv \frac { 1 } { 1 + e ^ { - z } }
$$

## Exercises
### (1)
$$
\mathrm{output} =
\left\\{
\begin{array}{}
0 & \mathrm{ if } \;w \cdot x + b \leq 0 \\\\\\
1 &  \mathrm{ if } \;w \cdot x + b \gt 0
\end{array}
\right.
$$
の$w$と$b$を定数倍しても不等号の向きは変化しないのでネットワークの振る舞いは変わらない

### (2)
$$
c \rightarrow \infty
$$
であっても(1)と同様に不等号の向きは変わらない。
$$
c \rightarrow \infty
$$
のとき
$$
\mathrm{output} =
\left\\{
\begin{array}{l}
z \rightarrow \infty & (z \gt 0) \\\\\\
z \rightarrow -\infty & (z \lt 0)
\end{array}
\right.
$$
よって
$$
\mathrm{output} =
\left\\{
\begin{array}{l}
σ \rightarrow 1 & (z \gt 0) \\\\\\
σ \rightarrow 0 & (z \lt 0)
\end{array}
\right.
$$
また、$z=0$となるパーセプトロンがあると$\sigma(z) = \frac{1}{2}$となりシグモイドニューロンのネットワークはパーセプトロンの場合と同じように振る舞うことはない

## ニューラルネットワークのアーキテクチャ

- 入力層
 - 入力ニューロン
- 出力層
 - 出力ニューロン
- 隠れ層

### 再帰型ニューラルネットワーク
フィードバックループを持つ再帰型ニューラルネットワークというモデルもあるが、学習アルゴリズムが非力であったのが大きな理由で主流ではない。しかし、非常に興味深い。人間の脳の働き方に近い。

### フィードフォワードニューラルネットワーク
ネットワーク内にループがない。情報は常に前に伝わり、後ろには戻らない。
ループを許さないニューラルネットワーク
現在、より広く使われているニューラルネットワーク

## エクササイズ
$$
w_1  = c[0.50, 1.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] \\\\\\
w_2 = c[0.00, 0.00, 0.33, 0.50, 0.50, 1.00, 0.00, 0.00, 0.00, 0.00] \\\\\\
w_3 = c[0.00, 0.00, 0.33, 0.50, 0.00, 0.00, 0.50, 1.00, 0.00, 0.00] \\\\\\
w_4 = c[0.50, 0.00, 0.33, 0.00, 0.50, 0.00, 0.50, 0.00, 1.00, 0.00] \\\\\\
b > -0.99c
$$
\\(c\\)はとても大きな数字・・・？

python3でやるときは↓のリポジトリで

https://github.com/MichalDanielDobrzanski/DeepLearningPython35



高度なアルゴリズム ≤ シンプルな学習アルゴリズム + 良い訓練データ